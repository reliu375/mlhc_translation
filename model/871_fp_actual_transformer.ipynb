{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"871_fp_actual_transformer.ipynb","provenance":[{"file_id":"1ehg1RNDanQG59sU5inCyqSqxZb8abgAn","timestamp":1620781786865},{"file_id":"1p1HI66I6QY0mbN4ufalN5BId8oBA-IaC","timestamp":1620518894919}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"id":"ATE92Xqa-K3X"},"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import math\n","import torch.nn.functional as F\n","import copy\n","import json\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FcD4eq1Lzsxf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620929616389,"user_tz":420,"elapsed":2222,"user":{"displayName":"Renbin Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDg7JBPfGJg4OqSmd6Xvej6r-SRxhyxgILgsfW=s64","userId":"05750027745545487753"}},"outputId":"5806126b-9c36-4745-a804-c137da3b2425"},"source":["# !pip install spacy==2.2.3"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting spacy==2.2.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/76/1f30264c433f9c3c84171fa03f4b6bb5f3303df7781d21554d25045873f4/spacy-2.2.3-cp37-cp37m-manylinux1_x86_64.whl (10.4MB)\n","\u001b[K     |████████████████████████████████| 10.4MB 4.1MB/s eta 0:00:01\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6wlR2Dl--K3b"},"source":["# Citations\n","# https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec\n","# https://pytorch.org/tutorials/beginner/transformer_tutorial.html"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CHQT1eyW-OoI","executionInfo":{"status":"ok","timestamp":1620929619989,"user_tz":420,"elapsed":1215,"user":{"displayName":"Renbin Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDg7JBPfGJg4OqSmd6Xvej6r-SRxhyxgILgsfW=s64","userId":"05750027745545487753"}},"outputId":"eceb4830-9052-4349-923b-d65ea0aaa902"},"source":["from google.colab import drive \n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTPxSstS_R2p","executionInfo":{"elapsed":296,"status":"ok","timestamp":1620781866133,"user":{"displayName":"Renbin Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDg7JBPfGJg4OqSmd6Xvej6r-SRxhyxgILgsfW=s64","userId":"05750027745545487753"},"user_tz":420},"outputId":"17d55ec0-1622-4c2b-d87a-2857e2475fce"},"source":["%%bash\n","pwd\n","ls\n","cd drive/MyDrive/6.871\\ NLP\\ Project/data\n","pwd\n","ls\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","drive\n","sample_data\n","/content\n","drive\n","sample_data\n"],"name":"stdout"},{"output_type":"stream","text":["bash: line 3: cd: drive/MyDrive/6.871 NLP Project/data: No such file or directory\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"jZW1XFgA-K3b"},"source":["device = \"cuda\" # change to \"cuda\" when moved to google colab?"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yVG-EIeN-K3c"},"source":["### Preprocessing ### "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-p3PxdU1-K3c"},"source":["# Constants for state of data processing\n","BLANK = 0\n","ORIGINAL = 1\n","REPHRASED = 2\n","TRANSLATED = 3\n","\n","def process_data(filename, test=False):\n","    state = ORIGINAL\n","    original_sents, translated_sents, rephrased_sents = [], [], []\n","    file = open(filename, 'r')\n","    while True:\n","        line = file.readline()\n","        # print(line, len(line))\n","        if not line: #EOF\n","            break \n","        if not test:\n","            if state == ORIGINAL: # Original sentence\n","                original_sents.append(line.strip())\n","                state = TRANSLATED\n","            elif state == TRANSLATED: # Translated sentence\n","                translated_sents.append(line.strip())\n","                state = BLANK\n","            elif state == BLANK: # Blank line\n","                assert line == '\\n' # If assertion fails, something wrong with the file format\n","                state = ORIGINAL\n","            else:\n","                raise ValueError('Unexpected state encountered.')\n","        else:\n","            if state == ORIGINAL: # Original sentence\n","                original_sents.append(line.strip())\n","                state = REPHRASED\n","            elif state == REPHRASED: # Translated sentence\n","                rephrased_sents.append(line.strip())\n","                state = TRANSLATED\n","            elif state == TRANSLATED: # Translated sentence\n","                translated_sents.append(line.strip())\n","                state = BLANK\n","            elif state == BLANK: # Blank line\n","                assert line == '\\n' # If assertion fails, something wrong with the file format\n","                state = ORIGINAL\n","            else:\n","                raise ValueError('Unexpected state encountered.')\n","   \n","    assert len(original_sents) == len(translated_sents) # all sents should be paired\n","    if test:\n","        assert len(original_sents) == len(rephrased_sents)\n","\n","    return {'original': original_sents, 'translated': translated_sents, 'rephrased': rephrased_sents}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5wGtoVgb-K3d","executionInfo":{"status":"ok","timestamp":1620929628490,"user_tz":420,"elapsed":2166,"user":{"displayName":"Renbin Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDg7JBPfGJg4OqSmd6Xvej6r-SRxhyxgILgsfW=s64","userId":"05750027745545487753"}},"outputId":"02cb37e0-9625-4233-8682-228dd6d0aa0e"},"source":["%%time\n","train = process_data('/content/drive/MyDrive/MedLane/train(12809)_new.txt')\n","test = process_data('/content/drive/MyDrive/MedLane/test(2030)_new.txt', test=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 36.9 ms, sys: 7.07 ms, total: 44 ms\n","Wall time: 1.48 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GDRdIbLB7ux0"},"source":["test['translated'] = [sentence[2:] for sentence in test['translated']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7fM0koBMA0p8"},"source":["import spacy\n","from collections import Counter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aV6vIU44-K3d","executionInfo":{"status":"ok","timestamp":1620929638186,"user_tz":420,"elapsed":1379,"user":{"displayName":"Renbin Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDg7JBPfGJg4OqSmd6Xvej6r-SRxhyxgILgsfW=s64","userId":"05750027745545487753"}},"outputId":"ec4b4021-2360-4a98-d256-8fac77a86fe7"},"source":["%%time\n","def tokenize_and_build_vocab(corpus, tokenization_func, special_tokens, min_freq = 0):\n","    vocab_counter = Counter()\n","    tokenized_sent = []\n","    for (i, sent) in enumerate(corpus):\n","        if i % 200 == 0: \n","          print('reached corpus sentence ' + str(i))\n","        token_list = tokenization_func(sent)\n","        tokenized_sent.append(token_list)\n","        vocab_counter.update(token_list)\n","        \n","    vocab_to_ix = {vocab: ix + len(special_tokens) for ix, (vocab, freq) in enumerate(vocab_counter.most_common()) if freq >= min_freq}\n","    \n","    for tok, ix in special_tokens.items():\n","        vocab_to_ix[tok] = ix\n","        \n","    return tokenized_sent, dict(vocab_counter.most_common()), vocab_to_ix\n","\n","def tokenize(lang_model, sentence):\n","    sentence = sentence.lower()\n","    sentence = [tok.text for tok in lang_model.tokenizer(sentence)]\n","\n","    return sentence\n","print('started')\n","lang_model = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner'])\n","print('lang model built')\n","tokenization_func = lambda x: tokenize(lang_model, x)\n","special_tokens = {'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3}\n","print('created tokenizer')\n","# train_src_sent, _, src_vocab_to_ix = tokenize_and_build_vocab(train['original'], tokenization_func, special_tokens)\n","# print('train src sentence done')\n","# train_tgt_sent, _, tgt_vocab_to_ix = tokenize_and_build_vocab(train['translated'], tokenization_func, special_tokens)\n","# print('train tgt sentence done')\n","\n","# test_src_sent, _, _ = tokenize_and_build_vocab(test['original'], tokenization_func, special_tokens)\n","# print('test src sentence done')\n","# test_tgt_sent, _, _ = tokenize_and_build_vocab(test['translated'], tokenization_func, special_tokens)\n","# print('test tgt sentence done')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["started\n","lang model built\n","created tokenizer\n","CPU times: user 455 ms, sys: 55.2 ms, total: 510 ms\n","Wall time: 509 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wNpS1I7EJ--D"},"source":["with open(\"/content/drive/MyDrive/MIT/6.871/6.871 NLP Project/data/train_src_sentsent.json\") as f:  \n","  train_src_sent = json.load(f)\n","\n","with open(\"/content/drive/MyDrive/MIT/6.871/6.871 NLP Project/data/train_src_sentmap.json\") as f:  \n","  src_vocab_to_ix = json.load(f)\n","\n","with open(\"/content/drive/MyDrive/MIT/6.871/6.871 NLP Project/data/train_tgt_sentsent.json\") as f:  \n","  train_tgt_sent = json.load(f)\n","\n","with open(\"/content/drive/MyDrive/MIT/6.871/6.871 NLP Project/data/train_tgt_sentmap.json\") as f:  \n","  tgt_vocab_to_ix = json.load(f)\n","\n","\n","with open(\"/content/drive/MyDrive/MIT/6.871/6.871 NLP Project/data/test_src_sentsent.json\") as f:  \n","  test_src_sent = json.load(f)\n","\n","with open(\"/content/drive/MyDrive/MIT/6.871/6.871 NLP Project/data/test_tgt_sentsent.json\") as f:  \n","  test_tgt_sent = json.load(f)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3GsQqcBs3PV"},"source":["test_tgt_sent = [sent[1:] for sent in test_tgt_sent]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nosEUjYc-K3e","executionInfo":{"status":"ok","timestamp":1620929648659,"user_tz":420,"elapsed":602,"user":{"displayName":"Renbin Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDg7JBPfGJg4OqSmd6Xvej6r-SRxhyxgILgsfW=s64","userId":"05750027745545487753"}},"outputId":"ffdfb981-8818-48c3-b31f-79251068dd14"},"source":["print(len(src_vocab_to_ix))\n","print(len(tgt_vocab_to_ix))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["12603\n","12225\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4vTb8c96-K3e"},"source":["from torch.utils import data\n","\n","# These IDs are reserved.\n","PAD_INDEX = 0\n","UNK_INDEX = 1\n","SOS_INDEX = 2\n","EOS_INDEX = 3\n","\n","class MTDataset(data.Dataset):\n","    def __init__(self, src_sents, src_vocab_map, tgt_sents, tgt_vocab_map, num_samples=1.):\n","        self.src_sents = src_sents[:int(len(src_sents) * num_samples)]\n","        self.tgt_sents = tgt_sents[:int(len(src_sents) * num_samples)]\n","        self.src_vocab_to_ix = src_vocab_map\n","        self.src_ix_to_vocab = {v: k for k, v in src_vocab_map.items()}\n","        self.tgt_vocab_to_ix = tgt_vocab_map\n","        self.tgt_ix_to_vocab = {v: k for k, v in tgt_vocab_map.items()}\n","        \n","        self.max_src_seq_len = 146 #max([len(sent) for sent in src_sents]) + 2\n","        self.max_tgt_seq_len = 146 #max(max([len(sent) for sent in tgt_sents]) + 2, self.max_src_seq_len)\n","        \n","        assert len(self.src_sents) == len(self.tgt_sents)\n","        \n","    def __getitem__(self, index):\n","        src_sent = self.src_sents[index]\n","        src_len = len(src_sent) + 2 # including <SOS> <EOS>\n","        src_ids = []\n","        for w in src_sent:\n","            if w not in self.src_vocab_to_ix:\n","                src_ids.append(UNK_INDEX)\n","            else:\n","                src_ids.append(self.src_vocab_to_ix[w])\n","        \n","        src_id = ([SOS_INDEX] + src_ids + [EOS_INDEX] + [PAD_INDEX] *\n","              (self.max_src_seq_len - src_len))\n","        \n","        tgt_sent = self.tgt_sents[index]\n","        tgt_len = len(tgt_sent) + 2\n","        tgt_ids = []\n","        for w in tgt_sent:\n","            if w not in self.tgt_vocab_to_ix:\n","                tgt_ids.append(UNK_INDEX)\n","            else:\n","                tgt_ids.append(self.tgt_vocab_to_ix[w])\n","                \n","        tgt_id = ([SOS_INDEX] + tgt_ids + [EOS_INDEX] + [PAD_INDEX] *\n","              (self.max_tgt_seq_len - tgt_len))\n","        \n","        \n","        return torch.tensor(src_id), src_len, torch.tensor(tgt_id), tgt_len\n","    \n","    def __len__(self):\n","        return len(self.src_sents)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eyyGZ14_-K3f","executionInfo":{"status":"ok","timestamp":1620929654263,"user_tz":420,"elapsed":693,"user":{"displayName":"Renbin Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDg7JBPfGJg4OqSmd6Xvej6r-SRxhyxgILgsfW=s64","userId":"05750027745545487753"}},"outputId":"4adcea86-d6c7-427f-f8a6-1732e613847e"},"source":["batch_size = 32\n","train_set = MTDataset(train_src_sent, src_vocab_to_ix, train_tgt_sent, tgt_vocab_to_ix, 1)\n","test_set  = MTDataset(test_src_sent, src_vocab_to_ix, test_tgt_sent, tgt_vocab_to_ix, 1)\n","\n","train_data_loader = data.DataLoader(train_set, batch_size=32, num_workers = 8, shuffle=True)\n","test_data_loader = data.DataLoader(test_set, batch_size=1, num_workers = 8, shuffle=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HD15Vk7rONK6","executionInfo":{"status":"ok","timestamp":1620929655934,"user_tz":420,"elapsed":1248,"user":{"displayName":"Renbin Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDg7JBPfGJg4OqSmd6Xvej6r-SRxhyxgILgsfW=s64","userId":"05750027745545487753"}},"outputId":"3ac03ee9-7485-4e94-ae27-d576ca284fd4"},"source":["print(train_set.max_src_seq_len)\n","print(train_set.max_tgt_seq_len)\n","print(test_set.max_src_seq_len)\n","print(test_set.max_tgt_seq_len)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["146\n","146\n","146\n","146\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aOjCXj98c8Qc"},"source":["# Model Code"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"clYnI32D-K3f"},"source":["# Masking functions\n","def subsequent_mask(size):\n","    attn_shape = (1, size, size)\n","    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n","    return torch.from_numpy(subsequent_mask) == 0\n","\n","def make_std_mask(tgt, pad):\n","    \"Create a mask to hide padding and future words.\"\n","    tgt_mask = (tgt != pad).unsqueeze(-2)\n","    tgt_mask = tgt_mask & Variable(\n","        subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n","    return tgt_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w4pLpGO4dTrF"},"source":["# Loss function/perplexity\n","import math\n","import time\n","\n","class SimpleLossCompute:\n","  \"\"\"A simple loss compute and train function.\"\"\"\n","\n","  def __init__(self, generator, criterion, opt=None):\n","    self.generator = generator\n","    self.criterion = criterion\n","    self.opt = opt\n","\n","  def __call__(self, x, y, norm):\n","    x = self.generator(x)\n","    loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n","                          y.contiguous().view(-1))\n","    loss = loss / norm\n","\n","    if self.opt is not None:  # training mode\n","      loss.backward()          \n","      self.opt.step()\n","      self.opt.zero_grad()\n","\n","    return loss.data.item() * norm\n","\n","def run_epoch(data_loader, model, loss_compute, print_every = 10):\n","    \"Standard Training and Logging Function\"\n","    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n","    start = time.time()\n","    total_tokens = 0\n","    total_loss = 0\n","    tokens = 0\n","    for i, batch in enumerate(data_loader):\n","        srcs, src_lens, tgts, tgt_lens = batch\n","        \n","        srcs_mask = srcs.unsqueeze(-2) != PAD_INDEX\n","        tgts_mask = make_std_mask(tgts[:,:-1], PAD_INDEX)\n","\n","        del tgt_lens\n","\n","        # print('source ids shape', srcs.shape)\n","        # print('target ids shape', tgts[:,:-1].shape)\n","        # print('source masks shape', srcs_mask.shape)\n","        # print('target masks shape', tgts_mask.shape)\n","\n","        out = model.forward(srcs.to(device), tgts[:,:-1].to(device), srcs_mask.to(device), tgts_mask.to(device))\n","        # print(out.size()) # seq_len = 47\n","        # print(tgts[:,1:].size()) # (bs x 46 x ...)\n","\n","        loss = loss_compute(out, tgts[:,1:].to(device), norm=srcs.size(0))\n","        total_loss += loss\n","        total_tokens += (tgts[:,1:] != PAD_INDEX).data.sum().item()\n","        \n","        if model.training and i % print_every == 0:\n","          print(\"Epoch Step: %d Loss: %f\" % (i, loss / srcs.size(0)))\n","          print(\"Epoch Step: %d Perplexity: %f\" % (i, math.exp(total_loss / float(total_tokens))))\n","\n","    return math.exp(total_loss / float(total_tokens))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ffbI4KafdbiY"},"source":["def train(model, num_epochs, learning_rate, print_every):\n","  # Set `ignore_index` as PAD_INDEX so that pad tokens won't be included when\n","  # computing the loss.\n","  criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n","  optim = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.98), eps=1e-9)\n","\n","  # Keep track of dev ppl for each epoch.\n","  dev_ppls = []\n","\n","  for epoch in range(num_epochs):\n","    print(\"Epoch\", epoch)\n","\n","    model.train()\n","    train_ppl = run_epoch(data_loader=train_data_loader, model=model,\n","                          loss_compute=SimpleLossCompute(model.generator,\n","                                                         criterion, optim),\n","                          print_every=print_every)\n","        \n","    model.eval()\n","    with torch.no_grad():      \n","      dev_ppl = run_epoch(data_loader=test_data_loader, model=model,\n","                          loss_compute=SimpleLossCompute(model.generator,\n","                                                         criterion, None),\n","                          print_every=print_every)\n","      print(\"Validation perplexity: %f\" % dev_ppl)\n","      dev_ppls.append(dev_ppl)\n","\n","  # torch.save(model, 'drive/My Drive/MIT/6.864/6.864 FP/transformer/model.pt')\n","        \n","  return dev_ppls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIuaRumsdcCM"},"source":["# Greedy decode algorithm:\n","def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    encoder_out = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n","    \n","    output = []\n","    for i in range(max_len-1):\n","        out = model.decode(ys, encoder_out, src_mask, subsequent_mask(ys.size(1)).type_as(src.data))\n","        prob = model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim = 1)\n","        next_word = next_word.data[0]\n","        if next_word == EOS_INDEX: \n","            break\n","        output.append(next_word)    \n","        ys = torch.cat([ys, \n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n","    \n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1_d9OWXDd43_"},"source":["# Model Implementation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uxGMMgEbd6ZZ"},"source":["from torch.autograd import Variable\n","\n","class PositionalEncoder(nn.Module):\n","  def __init__(self, d_model, max_seq_len=146):\n","    super().__init__()\n","    self.d_model = d_model\n","        \n","    # create constant 'pe' matrix with values dependant on \n","    # pos and i\n","    pe = torch.zeros(max_seq_len, d_model)\n","    for pos in range(max_seq_len):\n","      for i in range(0, d_model, 2):\n","        pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n","        pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n","\n","    pe = pe.unsqueeze(0)\n","    self.register_buffer('pe', pe)\n","\n","  def forward(self, x):\n","    x = x * math.sqrt(self.d_model) # conflict possible, check this line\n","\n","    seq_len = x.size(1)\n","    x = x + Variable(self.pe[:,:seq_len], requires_grad=False)# .cuda()\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pd2buCGQd-B3"},"source":["def attention(q, k, v, d_k, mask=None, dropout=None):\n","  scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n","\n","  if mask is not None:\n","    # print('mask size ', mask.size())\n","    # print('q size ', q.size())\n","    # print(scores.size())\n","    mask = mask.unsqueeze(1)\n","    # print(mask.size())\n","    scores = scores.masked_fill(mask==0, -1e9) # approximation\n","\n","  scores = F.softmax(scores, dim=-1)\n","\n","  if dropout is not None:\n","    scores = dropout(scores)\n","\n","  return torch.matmul(scores, v)\n","\n","class MultiHeadAttention(nn.Module):\n","  def __init__(self, heads, d_model, dropout = 0.1):\n","    super().__init__()\n","    self.d_model = d_model\n","    self.d_k = d_model // heads\n","    self.heads = heads\n","\n","    self.query = nn.Linear(d_model, d_model)\n","    self.key = nn.Linear(d_model, d_model)\n","    self.value = nn.Linear(d_model, d_model)\n","    self.dropout = nn.Dropout(dropout)\n","    self.out = nn.Linear(d_model, d_model)\n","\n","  def forward(self, q, k, v, mask=None):\n","    bs = q.size(0)\n","\n","    q = self.query(q).view(bs, -1, self.heads, self.d_k)\n","    k = self.key(k).view(bs, -1, self.heads, self.d_k)\n","    v = self.value(v).view(bs, -1, self.heads, self.d_k)\n","\n","    q = q.transpose(1, 2)\n","    k = k.transpose(1, 2)\n","    v = v.transpose(1, 2)\n","    scores = attention(q, k, v, self.d_k, mask, self.dropout)\n","\n","    concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n","\n","    return self.out(concat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KWeA0WyceCMc"},"source":["class FeedForward(nn.Module):\n","  def __init__(self, d_model, d_ff=2048, dropout=0.1):\n","    super().__init__()\n","\n","    self.l1 = nn.Linear(d_model, d_ff)\n","    self.dropout = nn.Dropout(dropout)\n","    self.l2 = nn.Linear(d_ff, d_model)\n","\n","  def forward(self, x):\n","    x = self.dropout(F.relu(self.l1(x)))\n","    return self.l2(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-OAPS__teFHr"},"source":["class LayerNorm(nn.Module):\n","  def __init__(self, d_model, eps=1e-6):\n","    super().__init__()\n","\n","    self.size = d_model\n","\n","    self.alpha = nn.Parameter(torch.ones(self.size))\n","    self.bias = nn.Parameter(torch.zeros(self.size))\n","    self.eps = eps\n","\n","  def forward(self, x):\n","    norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n","    return norm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wKSsjumUeKnT"},"source":["class EncoderLayer(nn.Module):\n","  def __init__(self, d_model, heads, d_ff = 2048, dropout=0.1):\n","    super().__init__()\n","    self.ln1 = LayerNorm(d_model)\n","    self.ln2 = LayerNorm(d_model)\n","    self.attn = MultiHeadAttention(heads, d_model, dropout)\n","    self.ff = FeedForward(d_model, d_ff, dropout)\n","    self.d1 = nn.Dropout(dropout)\n","    self.d2 = nn.Dropout(dropout)\n","\n","  def forward(self, x, mask):\n","    x2 = self.ln1(x)\n","    x = x + self.d1(self.attn(x2, x2, x2, mask))\n","    x2 = self.ln2(x)\n","    x = x + self.d2(self.ff(x2))\n","    return x\n","\n","class DecoderLayer(nn.Module):\n","  def __init__(self, d_model, heads, d_ff = 2048, dropout=0.1):\n","    super().__init__()\n","    self.ln1 = LayerNorm(d_model)\n","    self.ln2 = LayerNorm(d_model)\n","    self.ln3 = LayerNorm(d_model)\n","\n","    self.d1 = nn.Dropout(dropout)\n","    self.d2 = nn.Dropout(dropout)\n","    self.d3 = nn.Dropout(dropout)\n","\n","    self.attn1 = MultiHeadAttention(heads, d_model, dropout)\n","    self.attn2 = MultiHeadAttention(heads, d_model, dropout)\n","    self.ff = FeedForward(d_model, d_ff, dropout)\n","  \n","  def forward(self, x, encoder_out, src_mask, tgt_mask):\n","    x2 = self.ln1(x)\n","    # print('x2 shape ', x2.shape)\n","    x = x + self.d1(self.attn1(x2, x2, x2, tgt_mask))\n","    x2 = self.ln2(x)\n","    x = x + self.d2(self.attn2(x2, encoder_out, encoder_out, src_mask))\n","    x2 = self.ln3(x)\n","    return x + self.d3(self.ff(x2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VfW_9CIieOLw"},"source":["import copy\n","\n","def clone(module, N):\n","  return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n","\n","class Encoder(nn.Module):\n","  def __init__(self, vocab_size, d_model, N, heads, d_ff = 2048, dropout=0.1):\n","    super().__init__()\n","    self.N = N\n","    self.embed = nn.Embedding(vocab_size, d_model)\n","    self.pe = PositionalEncoder(d_model)\n","    self.layers = clone(EncoderLayer(d_model, heads, d_ff, dropout), self.N)\n","    self.ln = LayerNorm(d_model)\n","\n","  def forward(self, src, mask):\n","    x = self.embed(src)\n","    x = self.pe(x)\n","    for i in range(self.N):\n","      x = self.layers[i](x, mask)\n","\n","    return self.ln(x)\n","\n","class Decoder(nn.Module):\n","  def __init__(self, vocab_size, d_model, N, heads, d_ff = 2048, dropout=0.1):\n","    super().__init__()\n","    self.N = N\n","    self.embed = nn.Embedding(vocab_size, d_model)\n","    self.pe = PositionalEncoder(d_model)\n","    self.layers = clone(DecoderLayer(d_model, heads, d_ff, dropout), self.N)\n","    self.ln = LayerNorm(d_model)\n","\n","  def forward(self, tgt, encoder_out, src_mask, tgt_mask):\n","    x = self.embed(tgt)\n","    x = self.pe(x)\n","    for i in range(self.N):\n","      x = self.layers[i](x, encoder_out, src_mask, tgt_mask)\n","    return self.ln(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q4eUfGOwePbN"},"source":["class Generator(nn.Module):\n","  def __init__(self, d_model, vocab_size):\n","    super().__init__()\n","    self.proj = nn.Linear(d_model, vocab_size)\n","\n","  def forward(self, x):\n","    return F.log_softmax(self.proj(x), dim=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ALZ5NRQIeXmQ"},"source":["# Full Model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BML_jRYieddQ"},"source":["class ClinicalTextTranslationModel(nn.Module):\n","    \"\"\" Model class wrapping encoder + intermediate layers + decoder \"\"\"\n","    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, N, heads, d_ff = 2048, dropout=0.1, intermediate_layers=None):\n","        \n","        #self, hidden_size, num_heads, N, ff_size, dropout, max_seq_len,\n","        #         intermediate_layers, src_vocab_size, tgt_vocab_size):\n","        \n","        super().__init__()\n","        \n","        self.encoder = Encoder(src_vocab_size, d_model, N, heads, d_ff = 2048, dropout=0.1)\n","        self.intermediate_layers = intermediate_layers\n","        self.decoder = Decoder(tgt_vocab_size, d_model, N, heads, d_ff = 2048, dropout=0.1)\n","        \n","        self.generator = Generator(d_model, tgt_vocab_size)\n","    \n","    def forward(self, src, tgt, src_mask, tgt_mask):\n","        encoder_output = self.encoder(src, src_mask)\n","        \n","        intermediate_layer_output = encoder_output\n","        \n","        if self.intermediate_layers is not None:\n","            intermediate_layer_output = self.intermediate_layers(intermediate_output)\n","            \n","        decoder_output = self.decoder(tgt, intermediate_layer_output, src_mask, tgt_mask)\n","        \n","        return decoder_output\n","    \n","    def encode(self, src, src_mask):\n","        encoder_output = self.encoder(src, src_mask)\n","        \n","        intermediate_layer_output = encoder_output\n","        \n","        if self.intermediate_layers is not None:\n","            intermediate_layer_output = self.intermediate_layers(intermediate_output)\n","        \n","        return intermediate_layer_output\n","        \n","    def decode(self, tgt, intermediate_layer_output, src_mask,  tgt_mask):\n","        decoder_output = self.decoder(tgt, intermediate_layer_output, src_mask, tgt_mask)\n","        return decoder_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-z6dE68sfrBp"},"source":["def make_model(src_vocab, tgt_vocab, N=6, \n","               d_model=512, d_ff=2048, h=8, dropout=0.1):\n","    \"Helper: Construct a model from hyperparameters.\"\n","    model = ClinicalTextTranslationModel(src_vocab, tgt_vocab, d_model, N, h, d_ff, dropout).to(device)\n","    \n","    # This was important from their code. \n","    # Initialize parameters with Glorot / fan_avg.\n","    for p in model.parameters():\n","        if p.dim() > 1:\n","            nn.init.xavier_uniform(p)\n","    return model\n","\n","init = False\n","if init:\n","  model = make_model(len(src_vocab_to_ix), len(tgt_vocab_to_ix), N=6, d_model=512, d_ff=2048, h=8, dropout=0.1)\n","else:\n","  model = torch.load(\"/content/drive/MyDrive/MIT/6.871/6.871 NLP Project/data/model_basic.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4iXoRxif9hK","executionInfo":{"elapsed":1405738,"status":"ok","timestamp":1620927197676,"user":{"displayName":"Renbin Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDg7JBPfGJg4OqSmd6Xvej6r-SRxhyxgILgsfW=s64","userId":"05750027745545487753"},"user_tz":420},"outputId":"e0f4bb35-a328-437b-e5c4-0846cf8e0335"},"source":["ppls = train(model, 12, 0.0001, 20)\n","print(ppls)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch Step: 0 Loss: 206.339127\n","Epoch Step: 0 Perplexity: 11996.769394\n","Epoch Step: 20 Loss: 179.800339\n","Epoch Step: 20 Perplexity: 4997.286978\n","Epoch Step: 40 Loss: 182.253586\n","Epoch Step: 40 Perplexity: 3014.436313\n","Epoch Step: 60 Loss: 156.892822\n","Epoch Step: 60 Perplexity: 2000.512382\n","Epoch Step: 80 Loss: 137.776505\n","Epoch Step: 80 Perplexity: 1465.993901\n","Epoch Step: 100 Loss: 159.370438\n","Epoch Step: 100 Perplexity: 1191.680194\n","Epoch Step: 120 Loss: 182.255188\n","Epoch Step: 120 Perplexity: 1022.658433\n","Epoch Step: 140 Loss: 129.937592\n","Epoch Step: 140 Perplexity: 905.362860\n","Epoch Step: 160 Loss: 128.391739\n","Epoch Step: 160 Perplexity: 810.271117\n","Epoch Step: 180 Loss: 128.603592\n","Epoch Step: 180 Perplexity: 733.511344\n","Epoch Step: 200 Loss: 120.214699\n","Epoch Step: 200 Perplexity: 673.352757\n","Epoch Step: 220 Loss: 110.694077\n","Epoch Step: 220 Perplexity: 622.895538\n","Epoch Step: 240 Loss: 125.358139\n","Epoch Step: 240 Perplexity: 580.808730\n","Epoch Step: 260 Loss: 131.200592\n","Epoch Step: 260 Perplexity: 543.409531\n","Epoch Step: 280 Loss: 143.180161\n","Epoch Step: 280 Perplexity: 509.176154\n","Epoch Step: 300 Loss: 108.400162\n","Epoch Step: 300 Perplexity: 479.559482\n","Epoch Step: 320 Loss: 117.186783\n","Epoch Step: 320 Perplexity: 454.530942\n","Epoch Step: 340 Loss: 117.278931\n","Epoch Step: 340 Perplexity: 429.819056\n","Epoch Step: 360 Loss: 107.586807\n","Epoch Step: 360 Perplexity: 407.263367\n","Epoch Step: 380 Loss: 113.032104\n","Epoch Step: 380 Perplexity: 388.218656\n","Epoch Step: 400 Loss: 256.006470\n","Epoch Step: 400 Perplexity: 370.933189\n","Validation perplexity: 294.814263\n","Epoch 1\n","Epoch Step: 0 Loss: 111.064461\n","Epoch Step: 0 Perplexity: 125.896421\n","Epoch Step: 20 Loss: 105.999207\n","Epoch Step: 20 Perplexity: 128.898504\n","Epoch Step: 40 Loss: 106.877403\n","Epoch Step: 40 Perplexity: 130.744595\n","Epoch Step: 60 Loss: 114.644951\n","Epoch Step: 60 Perplexity: 125.741279\n","Epoch Step: 80 Loss: 126.640137\n","Epoch Step: 80 Perplexity: 124.994264\n","Epoch Step: 100 Loss: 106.691559\n","Epoch Step: 100 Perplexity: 123.842407\n","Epoch Step: 120 Loss: 104.235474\n","Epoch Step: 120 Perplexity: 120.878856\n","Epoch Step: 140 Loss: 116.119759\n","Epoch Step: 140 Perplexity: 117.478914\n","Epoch Step: 160 Loss: 103.828018\n","Epoch Step: 160 Perplexity: 115.003812\n","Epoch Step: 180 Loss: 108.424377\n","Epoch Step: 180 Perplexity: 111.690099\n","Epoch Step: 200 Loss: 107.945778\n","Epoch Step: 200 Perplexity: 109.588749\n","Epoch Step: 220 Loss: 118.634285\n","Epoch Step: 220 Perplexity: 107.826089\n","Epoch Step: 240 Loss: 89.984840\n","Epoch Step: 240 Perplexity: 105.089763\n","Epoch Step: 260 Loss: 99.614815\n","Epoch Step: 260 Perplexity: 103.227048\n","Epoch Step: 280 Loss: 98.515518\n","Epoch Step: 280 Perplexity: 101.356750\n","Epoch Step: 300 Loss: 119.523170\n","Epoch Step: 300 Perplexity: 99.242599\n","Epoch Step: 320 Loss: 94.447266\n","Epoch Step: 320 Perplexity: 97.537696\n","Epoch Step: 340 Loss: 103.967110\n","Epoch Step: 340 Perplexity: 95.596004\n","Epoch Step: 360 Loss: 100.519249\n","Epoch Step: 360 Perplexity: 93.541789\n","Epoch Step: 380 Loss: 96.464882\n","Epoch Step: 380 Perplexity: 91.653632\n","Epoch Step: 400 Loss: 46.399548\n","Epoch Step: 400 Perplexity: 90.066580\n","Validation perplexity: 162.468526\n","Epoch 2\n","Epoch Step: 0 Loss: 91.780640\n","Epoch Step: 0 Perplexity: 41.169463\n","Epoch Step: 20 Loss: 107.249710\n","Epoch Step: 20 Perplexity: 50.410036\n","Epoch Step: 40 Loss: 86.521492\n","Epoch Step: 40 Perplexity: 50.017541\n","Epoch Step: 60 Loss: 90.958336\n","Epoch Step: 60 Perplexity: 48.329134\n","Epoch Step: 80 Loss: 102.607712\n","Epoch Step: 80 Perplexity: 47.787861\n","Epoch Step: 100 Loss: 107.119064\n","Epoch Step: 100 Perplexity: 48.056778\n","Epoch Step: 120 Loss: 88.187584\n","Epoch Step: 120 Perplexity: 46.644659\n","Epoch Step: 140 Loss: 85.491753\n","Epoch Step: 140 Perplexity: 46.033422\n","Epoch Step: 160 Loss: 90.934990\n","Epoch Step: 160 Perplexity: 45.245498\n","Epoch Step: 180 Loss: 80.480316\n","Epoch Step: 180 Perplexity: 44.688400\n","Epoch Step: 200 Loss: 80.205582\n","Epoch Step: 200 Perplexity: 43.979689\n","Epoch Step: 220 Loss: 74.502007\n","Epoch Step: 220 Perplexity: 43.436216\n","Epoch Step: 240 Loss: 96.652725\n","Epoch Step: 240 Perplexity: 43.052798\n","Epoch Step: 260 Loss: 85.163177\n","Epoch Step: 260 Perplexity: 42.404799\n","Epoch Step: 280 Loss: 88.924736\n","Epoch Step: 280 Perplexity: 41.778237\n","Epoch Step: 300 Loss: 85.373062\n","Epoch Step: 300 Perplexity: 41.137657\n","Epoch Step: 320 Loss: 81.462296\n","Epoch Step: 320 Perplexity: 40.393662\n","Epoch Step: 340 Loss: 96.020676\n","Epoch Step: 340 Perplexity: 39.846108\n","Epoch Step: 360 Loss: 77.663551\n","Epoch Step: 360 Perplexity: 39.214341\n","Epoch Step: 380 Loss: 73.216194\n","Epoch Step: 380 Perplexity: 38.653858\n","Epoch Step: 400 Loss: 168.064514\n","Epoch Step: 400 Perplexity: 38.166430\n","Validation perplexity: 114.073204\n","Epoch 3\n","Epoch Step: 0 Loss: 89.604523\n","Epoch Step: 0 Perplexity: 31.778801\n","Epoch Step: 20 Loss: 67.601677\n","Epoch Step: 20 Perplexity: 25.386986\n","Epoch Step: 40 Loss: 72.747505\n","Epoch Step: 40 Perplexity: 23.773214\n","Epoch Step: 60 Loss: 81.950745\n","Epoch Step: 60 Perplexity: 23.458379\n","Epoch Step: 80 Loss: 70.142998\n","Epoch Step: 80 Perplexity: 23.193202\n","Epoch Step: 100 Loss: 59.457958\n","Epoch Step: 100 Perplexity: 22.459530\n","Epoch Step: 120 Loss: 65.892578\n","Epoch Step: 120 Perplexity: 22.442851\n","Epoch Step: 140 Loss: 64.746574\n","Epoch Step: 140 Perplexity: 22.136593\n","Epoch Step: 160 Loss: 79.561874\n","Epoch Step: 160 Perplexity: 21.873055\n","Epoch Step: 180 Loss: 73.522682\n","Epoch Step: 180 Perplexity: 21.530956\n","Epoch Step: 200 Loss: 62.985271\n","Epoch Step: 200 Perplexity: 21.089176\n","Epoch Step: 220 Loss: 86.610596\n","Epoch Step: 220 Perplexity: 20.847626\n","Epoch Step: 240 Loss: 69.783089\n","Epoch Step: 240 Perplexity: 20.608457\n","Epoch Step: 260 Loss: 58.045692\n","Epoch Step: 260 Perplexity: 20.223273\n","Epoch Step: 280 Loss: 52.730625\n","Epoch Step: 280 Perplexity: 20.005950\n","Epoch Step: 300 Loss: 57.363327\n","Epoch Step: 300 Perplexity: 19.803740\n","Epoch Step: 320 Loss: 73.087662\n","Epoch Step: 320 Perplexity: 19.610236\n","Epoch Step: 340 Loss: 70.530273\n","Epoch Step: 340 Perplexity: 19.456826\n","Epoch Step: 360 Loss: 87.669418\n","Epoch Step: 360 Perplexity: 19.274551\n","Epoch Step: 380 Loss: 71.281525\n","Epoch Step: 380 Perplexity: 19.044381\n","Epoch Step: 400 Loss: 97.483772\n","Epoch Step: 400 Perplexity: 18.794894\n","Validation perplexity: 101.607034\n","Epoch 4\n","Epoch Step: 0 Loss: 61.785702\n","Epoch Step: 0 Perplexity: 15.882759\n","Epoch Step: 20 Loss: 55.562870\n","Epoch Step: 20 Perplexity: 13.343260\n","Epoch Step: 40 Loss: 57.676689\n","Epoch Step: 40 Perplexity: 12.677436\n","Epoch Step: 60 Loss: 67.125366\n","Epoch Step: 60 Perplexity: 12.401790\n","Epoch Step: 80 Loss: 39.299496\n","Epoch Step: 80 Perplexity: 12.293145\n","Epoch Step: 100 Loss: 66.653091\n","Epoch Step: 100 Perplexity: 12.066648\n","Epoch Step: 120 Loss: 59.543880\n","Epoch Step: 120 Perplexity: 11.903963\n","Epoch Step: 140 Loss: 51.556229\n","Epoch Step: 140 Perplexity: 11.857486\n","Epoch Step: 160 Loss: 61.459663\n","Epoch Step: 160 Perplexity: 11.672095\n","Epoch Step: 180 Loss: 38.769711\n","Epoch Step: 180 Perplexity: 11.515469\n","Epoch Step: 200 Loss: 41.692429\n","Epoch Step: 200 Perplexity: 11.369573\n","Epoch Step: 220 Loss: 56.972954\n","Epoch Step: 220 Perplexity: 11.290625\n","Epoch Step: 240 Loss: 58.158684\n","Epoch Step: 240 Perplexity: 11.089339\n","Epoch Step: 260 Loss: 57.587719\n","Epoch Step: 260 Perplexity: 10.985639\n","Epoch Step: 280 Loss: 55.539146\n","Epoch Step: 280 Perplexity: 10.909178\n","Epoch Step: 300 Loss: 54.251453\n","Epoch Step: 300 Perplexity: 10.847001\n","Epoch Step: 320 Loss: 47.782726\n","Epoch Step: 320 Perplexity: 10.774241\n","Epoch Step: 340 Loss: 52.414215\n","Epoch Step: 340 Perplexity: 10.702441\n","Epoch Step: 360 Loss: 54.363338\n","Epoch Step: 360 Perplexity: 10.646374\n","Epoch Step: 380 Loss: 41.830997\n","Epoch Step: 380 Perplexity: 10.564607\n","Epoch Step: 400 Loss: 13.892591\n","Epoch Step: 400 Perplexity: 10.505699\n","Validation perplexity: 91.353697\n","Epoch 5\n","Epoch Step: 0 Loss: 49.266220\n","Epoch Step: 0 Perplexity: 8.904643\n","Epoch Step: 20 Loss: 51.679066\n","Epoch Step: 20 Perplexity: 7.856612\n","Epoch Step: 40 Loss: 40.998791\n","Epoch Step: 40 Perplexity: 7.432576\n","Epoch Step: 60 Loss: 47.873421\n","Epoch Step: 60 Perplexity: 7.227300\n","Epoch Step: 80 Loss: 52.291317\n","Epoch Step: 80 Perplexity: 7.147059\n","Epoch Step: 100 Loss: 49.717674\n","Epoch Step: 100 Perplexity: 7.083258\n","Epoch Step: 120 Loss: 53.124592\n","Epoch Step: 120 Perplexity: 7.145776\n","Epoch Step: 140 Loss: 46.267700\n","Epoch Step: 140 Perplexity: 7.094233\n","Epoch Step: 160 Loss: 31.689955\n","Epoch Step: 160 Perplexity: 6.988563\n","Epoch Step: 180 Loss: 54.202427\n","Epoch Step: 180 Perplexity: 6.995352\n","Epoch Step: 200 Loss: 39.943985\n","Epoch Step: 200 Perplexity: 7.000611\n","Epoch Step: 220 Loss: 55.353626\n","Epoch Step: 220 Perplexity: 7.054580\n","Epoch Step: 240 Loss: 51.551857\n","Epoch Step: 240 Perplexity: 7.023849\n","Epoch Step: 260 Loss: 38.038292\n","Epoch Step: 260 Perplexity: 6.952503\n","Epoch Step: 280 Loss: 44.237324\n","Epoch Step: 280 Perplexity: 6.901272\n","Epoch Step: 300 Loss: 44.134365\n","Epoch Step: 300 Perplexity: 6.877582\n","Epoch Step: 320 Loss: 38.111595\n","Epoch Step: 320 Perplexity: 6.861147\n","Epoch Step: 340 Loss: 36.706085\n","Epoch Step: 340 Perplexity: 6.868131\n","Epoch Step: 360 Loss: 45.220329\n","Epoch Step: 360 Perplexity: 6.799385\n","Epoch Step: 380 Loss: 42.674648\n","Epoch Step: 380 Perplexity: 6.739668\n","Epoch Step: 400 Loss: 23.981205\n","Epoch Step: 400 Perplexity: 6.698321\n","Validation perplexity: 53.652333\n","Epoch 6\n","Epoch Step: 0 Loss: 34.094070\n","Epoch Step: 0 Perplexity: 4.648916\n","Epoch Step: 20 Loss: 48.977638\n","Epoch Step: 20 Perplexity: 5.303146\n","Epoch Step: 40 Loss: 36.823120\n","Epoch Step: 40 Perplexity: 5.121727\n","Epoch Step: 60 Loss: 43.755867\n","Epoch Step: 60 Perplexity: 5.048283\n","Epoch Step: 80 Loss: 38.887512\n","Epoch Step: 80 Perplexity: 5.065834\n","Epoch Step: 100 Loss: 50.933094\n","Epoch Step: 100 Perplexity: 5.094740\n","Epoch Step: 120 Loss: 55.023678\n","Epoch Step: 120 Perplexity: 5.176152\n","Epoch Step: 140 Loss: 28.172703\n","Epoch Step: 140 Perplexity: 5.113317\n","Epoch Step: 160 Loss: 33.244019\n","Epoch Step: 160 Perplexity: 5.085556\n","Epoch Step: 180 Loss: 34.199265\n","Epoch Step: 180 Perplexity: 5.038903\n","Epoch Step: 200 Loss: 41.857067\n","Epoch Step: 200 Perplexity: 4.986818\n","Epoch Step: 220 Loss: 22.228344\n","Epoch Step: 220 Perplexity: 4.971941\n","Epoch Step: 240 Loss: 30.799507\n","Epoch Step: 240 Perplexity: 4.933796\n","Epoch Step: 260 Loss: 43.927811\n","Epoch Step: 260 Perplexity: 4.900268\n","Epoch Step: 280 Loss: 42.673897\n","Epoch Step: 280 Perplexity: 4.893096\n","Epoch Step: 300 Loss: 54.671917\n","Epoch Step: 300 Perplexity: 4.908347\n","Epoch Step: 320 Loss: 38.605957\n","Epoch Step: 320 Perplexity: 4.877389\n","Epoch Step: 340 Loss: 27.063496\n","Epoch Step: 340 Perplexity: 4.880324\n","Epoch Step: 360 Loss: 39.541058\n","Epoch Step: 360 Perplexity: 4.869198\n","Epoch Step: 380 Loss: 28.320679\n","Epoch Step: 380 Perplexity: 4.864742\n","Epoch Step: 400 Loss: 14.330318\n","Epoch Step: 400 Perplexity: 4.849372\n","Validation perplexity: 52.195574\n","Epoch 7\n","Epoch Step: 0 Loss: 27.078608\n","Epoch Step: 0 Perplexity: 3.472912\n","Epoch Step: 20 Loss: 29.387302\n","Epoch Step: 20 Perplexity: 3.926574\n","Epoch Step: 40 Loss: 35.631268\n","Epoch Step: 40 Perplexity: 4.008759\n","Epoch Step: 60 Loss: 24.105892\n","Epoch Step: 60 Perplexity: 3.940355\n","Epoch Step: 80 Loss: 37.266670\n","Epoch Step: 80 Perplexity: 3.950435\n","Epoch Step: 100 Loss: 31.870384\n","Epoch Step: 100 Perplexity: 3.919441\n","Epoch Step: 120 Loss: 27.449343\n","Epoch Step: 120 Perplexity: 3.889746\n","Epoch Step: 140 Loss: 32.494450\n","Epoch Step: 140 Perplexity: 3.885715\n","Epoch Step: 160 Loss: 29.310318\n","Epoch Step: 160 Perplexity: 3.861343\n","Epoch Step: 180 Loss: 31.749775\n","Epoch Step: 180 Perplexity: 3.838161\n","Epoch Step: 200 Loss: 41.451149\n","Epoch Step: 200 Perplexity: 3.823452\n","Epoch Step: 220 Loss: 62.486191\n","Epoch Step: 220 Perplexity: 3.824796\n","Epoch Step: 240 Loss: 46.356461\n","Epoch Step: 240 Perplexity: 3.827438\n","Epoch Step: 260 Loss: 24.745306\n","Epoch Step: 260 Perplexity: 3.809672\n","Epoch Step: 280 Loss: 26.081947\n","Epoch Step: 280 Perplexity: 3.799036\n","Epoch Step: 300 Loss: 33.157551\n","Epoch Step: 300 Perplexity: 3.801279\n","Epoch Step: 320 Loss: 31.922091\n","Epoch Step: 320 Perplexity: 3.796802\n","Epoch Step: 340 Loss: 23.571810\n","Epoch Step: 340 Perplexity: 3.784761\n","Epoch Step: 360 Loss: 33.280022\n","Epoch Step: 360 Perplexity: 3.780783\n","Epoch Step: 380 Loss: 33.807404\n","Epoch Step: 380 Perplexity: 3.784157\n","Epoch Step: 400 Loss: 46.464931\n","Epoch Step: 400 Perplexity: 3.769949\n","Validation perplexity: 54.744582\n","Epoch 8\n","Epoch Step: 0 Loss: 30.348917\n","Epoch Step: 0 Perplexity: 3.306917\n","Epoch Step: 20 Loss: 29.339588\n","Epoch Step: 20 Perplexity: 3.232427\n","Epoch Step: 40 Loss: 36.803333\n","Epoch Step: 40 Perplexity: 3.257335\n","Epoch Step: 60 Loss: 40.417919\n","Epoch Step: 60 Perplexity: 3.259897\n","Epoch Step: 80 Loss: 22.288752\n","Epoch Step: 80 Perplexity: 3.234318\n","Epoch Step: 100 Loss: 29.412107\n","Epoch Step: 100 Perplexity: 3.209145\n","Epoch Step: 120 Loss: 34.411007\n","Epoch Step: 120 Perplexity: 3.209667\n","Epoch Step: 140 Loss: 34.961487\n","Epoch Step: 140 Perplexity: 3.181924\n","Epoch Step: 160 Loss: 12.613106\n","Epoch Step: 160 Perplexity: 3.171330\n","Epoch Step: 180 Loss: 22.053085\n","Epoch Step: 180 Perplexity: 3.164483\n","Epoch Step: 200 Loss: 20.788345\n","Epoch Step: 200 Perplexity: 3.183333\n","Epoch Step: 220 Loss: 33.693024\n","Epoch Step: 220 Perplexity: 3.156010\n","Epoch Step: 240 Loss: 32.131485\n","Epoch Step: 240 Perplexity: 3.158823\n","Epoch Step: 260 Loss: 31.007698\n","Epoch Step: 260 Perplexity: 3.151840\n","Epoch Step: 280 Loss: 28.028490\n","Epoch Step: 280 Perplexity: 3.147985\n","Epoch Step: 300 Loss: 26.824682\n","Epoch Step: 300 Perplexity: 3.140914\n","Epoch Step: 320 Loss: 26.284794\n","Epoch Step: 320 Perplexity: 3.138556\n","Epoch Step: 340 Loss: 22.038193\n","Epoch Step: 340 Perplexity: 3.131674\n","Epoch Step: 360 Loss: 31.621889\n","Epoch Step: 360 Perplexity: 3.127467\n","Epoch Step: 380 Loss: 23.304127\n","Epoch Step: 380 Perplexity: 3.132534\n","Epoch Step: 400 Loss: 34.946732\n","Epoch Step: 400 Perplexity: 3.131961\n","Validation perplexity: 40.580408\n","Epoch 9\n","Epoch Step: 0 Loss: 16.961607\n","Epoch Step: 0 Perplexity: 2.134133\n","Epoch Step: 20 Loss: 25.121021\n","Epoch Step: 20 Perplexity: 2.613487\n","Epoch Step: 40 Loss: 24.129272\n","Epoch Step: 40 Perplexity: 2.727559\n","Epoch Step: 60 Loss: 26.124208\n","Epoch Step: 60 Perplexity: 2.742810\n","Epoch Step: 80 Loss: 26.561998\n","Epoch Step: 80 Perplexity: 2.752384\n","Epoch Step: 100 Loss: 17.854780\n","Epoch Step: 100 Perplexity: 2.720216\n","Epoch Step: 120 Loss: 44.889996\n","Epoch Step: 120 Perplexity: 2.728785\n","Epoch Step: 140 Loss: 25.020451\n","Epoch Step: 140 Perplexity: 2.741537\n","Epoch Step: 160 Loss: 21.402431\n","Epoch Step: 160 Perplexity: 2.732471\n","Epoch Step: 180 Loss: 19.076166\n","Epoch Step: 180 Perplexity: 2.714125\n","Epoch Step: 200 Loss: 22.281385\n","Epoch Step: 200 Perplexity: 2.708891\n","Epoch Step: 220 Loss: 19.143593\n","Epoch Step: 220 Perplexity: 2.696531\n","Epoch Step: 240 Loss: 27.306721\n","Epoch Step: 240 Perplexity: 2.691120\n","Epoch Step: 260 Loss: 24.098473\n","Epoch Step: 260 Perplexity: 2.691612\n","Epoch Step: 280 Loss: 20.232187\n","Epoch Step: 280 Perplexity: 2.682119\n","Epoch Step: 300 Loss: 22.429556\n","Epoch Step: 300 Perplexity: 2.689501\n","Epoch Step: 320 Loss: 27.186804\n","Epoch Step: 320 Perplexity: 2.694408\n","Epoch Step: 340 Loss: 20.349802\n","Epoch Step: 340 Perplexity: 2.697885\n","Epoch Step: 360 Loss: 22.526485\n","Epoch Step: 360 Perplexity: 2.691631\n","Epoch Step: 380 Loss: 18.830910\n","Epoch Step: 380 Perplexity: 2.687578\n","Epoch Step: 400 Loss: 30.883783\n","Epoch Step: 400 Perplexity: 2.690887\n","Validation perplexity: 46.067421\n","Epoch 10\n","Epoch Step: 0 Loss: 24.680201\n","Epoch Step: 0 Perplexity: 2.842445\n","Epoch Step: 20 Loss: 18.611162\n","Epoch Step: 20 Perplexity: 2.494371\n","Epoch Step: 40 Loss: 16.762295\n","Epoch Step: 40 Perplexity: 2.440833\n","Epoch Step: 60 Loss: 19.515825\n","Epoch Step: 60 Perplexity: 2.396150\n","Epoch Step: 80 Loss: 16.139025\n","Epoch Step: 80 Perplexity: 2.363005\n","Epoch Step: 100 Loss: 23.629383\n","Epoch Step: 100 Perplexity: 2.341247\n","Epoch Step: 120 Loss: 17.084650\n","Epoch Step: 120 Perplexity: 2.336516\n","Epoch Step: 140 Loss: 25.610416\n","Epoch Step: 140 Perplexity: 2.355949\n","Epoch Step: 160 Loss: 17.772301\n","Epoch Step: 160 Perplexity: 2.338722\n","Epoch Step: 180 Loss: 26.741785\n","Epoch Step: 180 Perplexity: 2.333069\n","Epoch Step: 200 Loss: 21.294317\n","Epoch Step: 200 Perplexity: 2.353921\n","Epoch Step: 220 Loss: 18.701000\n","Epoch Step: 220 Perplexity: 2.356922\n","Epoch Step: 240 Loss: 24.697979\n","Epoch Step: 240 Perplexity: 2.356561\n","Epoch Step: 260 Loss: 22.933929\n","Epoch Step: 260 Perplexity: 2.351287\n","Epoch Step: 280 Loss: 23.570972\n","Epoch Step: 280 Perplexity: 2.352504\n","Epoch Step: 300 Loss: 22.384903\n","Epoch Step: 300 Perplexity: 2.359920\n","Epoch Step: 320 Loss: 27.552855\n","Epoch Step: 320 Perplexity: 2.366815\n","Epoch Step: 340 Loss: 22.798872\n","Epoch Step: 340 Perplexity: 2.369249\n","Epoch Step: 360 Loss: 18.890280\n","Epoch Step: 360 Perplexity: 2.366163\n","Epoch Step: 380 Loss: 15.762194\n","Epoch Step: 380 Perplexity: 2.362119\n","Epoch Step: 400 Loss: 4.232027\n","Epoch Step: 400 Perplexity: 2.359417\n","Validation perplexity: 45.346096\n","Epoch 11\n","Epoch Step: 0 Loss: 16.003532\n","Epoch Step: 0 Perplexity: 1.963485\n","Epoch Step: 20 Loss: 25.223358\n","Epoch Step: 20 Perplexity: 2.167847\n","Epoch Step: 40 Loss: 21.365402\n","Epoch Step: 40 Perplexity: 2.168714\n","Epoch Step: 60 Loss: 25.896271\n","Epoch Step: 60 Perplexity: 2.153027\n","Epoch Step: 80 Loss: 17.212549\n","Epoch Step: 80 Perplexity: 2.135623\n","Epoch Step: 100 Loss: 13.883387\n","Epoch Step: 100 Perplexity: 2.127405\n","Epoch Step: 120 Loss: 20.918503\n","Epoch Step: 120 Perplexity: 2.130477\n","Epoch Step: 140 Loss: 19.298035\n","Epoch Step: 140 Perplexity: 2.141970\n","Epoch Step: 160 Loss: 11.643699\n","Epoch Step: 160 Perplexity: 2.134851\n","Epoch Step: 180 Loss: 10.171408\n","Epoch Step: 180 Perplexity: 2.141234\n","Epoch Step: 200 Loss: 26.019989\n","Epoch Step: 200 Perplexity: 2.152433\n","Epoch Step: 220 Loss: 22.250050\n","Epoch Step: 220 Perplexity: 2.151168\n","Epoch Step: 240 Loss: 16.048851\n","Epoch Step: 240 Perplexity: 2.156760\n","Epoch Step: 260 Loss: 14.623984\n","Epoch Step: 260 Perplexity: 2.147291\n","Epoch Step: 280 Loss: 22.593468\n","Epoch Step: 280 Perplexity: 2.150860\n","Epoch Step: 300 Loss: 24.813402\n","Epoch Step: 300 Perplexity: 2.149063\n","Epoch Step: 320 Loss: 15.888967\n","Epoch Step: 320 Perplexity: 2.144855\n","Epoch Step: 340 Loss: 24.150841\n","Epoch Step: 340 Perplexity: 2.141615\n","Epoch Step: 360 Loss: 14.789382\n","Epoch Step: 360 Perplexity: 2.142959\n","Epoch Step: 380 Loss: 29.318087\n","Epoch Step: 380 Perplexity: 2.140581\n","Epoch Step: 400 Loss: 99.727837\n","Epoch Step: 400 Perplexity: 2.135867\n","Validation perplexity: 31.886361\n","[294.8142626209206, 162.46852581683282, 114.07320407893653, 101.60703361815811, 91.35369723423099, 53.65233338136416, 52.19557375869936, 54.744582323483456, 40.580407575802, 46.06742087833696, 45.3460955810196, 31.88636069675095]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"axHenfVGxO9w"},"source":["torch.save(model, \"/content/drive/MyDrive/MIT/6.871/6.871 NLP Project/data/model_basic.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L0V5KolZ-Prb"},"source":["model = torch.load(\"/content/drive/MyDrive/MIT/6.871/6.871 NLP Project/data/model_basic.pt\", map_location=torch.device('cpu'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZBny4PW1yb9F"},"source":["!pip -q install sacrebleu\n","import sacrebleu\n","from tqdm import tqdm\n","\n","def compute_BLEU(model, data_loader, decoder, max_iters):\n","  bleu_scores = []\n","\n","  for i, batch in enumerate(test_data_loader):\n","    if i >= max_iters: break\n","    srcs, src_lens, tgts, tgt_lens = batch\n","          \n","    srcs_mask = srcs.unsqueeze(-2) != PAD_INDEX\n","\n","    src_ix_to_vocab = train_set.src_ix_to_vocab\n","\n","    src_sent = \" \".join([src_ix_to_vocab[ix.item()] for ix in srcs[0]])\n","    print('Source sent: ', src_sent)    \n","    \n","    out = decoder(model, srcs.to(device), srcs_mask.to(device), 146, SOS_INDEX)\n","\n","    tgts = tgts[0,1:]\n","    print(np.where(tgts == EOS_INDEX)[0][0])\n","    tgts = tgts[:np.where(tgts == EOS_INDEX)[0][0]]\n","    \n","    tgt_ix_to_vocab = train_set.tgt_ix_to_vocab\n","    \n","    tgt_sent = \" \".join([tgt_ix_to_vocab[ix.item()] for ix in tgts])\n","    out_sent = \" \".join([tgt_ix_to_vocab[ix.item()] for ix in out])\n","    print('Target Tokens: ', tgt_sent)\n","    print('Out tokens: ', out_sent)\n","\n","    bleu_scores.append(sacrebleu.raw_corpus_bleu([out_sent], [[tgt_sent]], .01).score)\n","\n","  return bleu_scores\n","\n","# print('BLEU score: %f' % (np.mean(compute_BLEU(model, \n","#                                            test_data_loader,\n","#                                             greedy_decode))))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FjX15Q7B3g3u"},"source":["scores = compute_BLEU(model, test_data_loader, greedy_decode, 25000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zEzRNx7lvXaP","executionInfo":{"status":"ok","timestamp":1620930874514,"user_tz":420,"elapsed":1486,"user":{"displayName":"Renbin Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjDg7JBPfGJg4OqSmd6Xvej6r-SRxhyxgILgsfW=s64","userId":"05750027745545487753"}},"outputId":"6042868d-428f-4e38-fd80-f28b5880bf2d"},"source":["\"\"\"\n","Potential Improvements/Experiments\n"," - Try BERT tokenizers e.g ClinicalBERT\n"," - start with ClincalBERT/BioBERT/BEHRT pretrained embeddings\n"," - Intermediate layers?\n"," - try varying N, adjust hyperparams\n"," - make a validation set from part of the training examples?\n"," - \"Tunability\" - Use only most common words/words with low enough reading scores\n"," - Front-load any UI that you can!\n","\"\"\"\n","print(np.mean(scores))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["55.05636930290187\n"],"name":"stdout"}]}]}